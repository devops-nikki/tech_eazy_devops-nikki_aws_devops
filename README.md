# Techeazy AWS Internship-DEVOPS ASSIGNMENT-1 
#  EC2 Java App Deployment with Terraform

## ğŸ“Œ Overview

This project automates the deployment of a Java 21 application on an AWS EC2 instance using Terraform. The setup installs dependencies, deploys the app, and verifies it is running on **port 80**.

## ğŸ› ï¸ Tech Stack

- **AWS EC2**
- **Terraform**
- **Java 21**
- **Postman** (for testing API endpoints)

## ğŸš€ Steps to Deploy

1. **Clone this repo:**
   
   `git clone https://github.com/devops-nikki/tech_eazy_devops-nikki_aws_devops.git`   
   `cd tech_eazy_devops-nikki_aws_devops`

2. **Set your AWS credentials as environment variables:**

   `-export AWS_ACCESS_KEY_ID=your_key`

   `-export AWS_SECRET_ACCESS_KEY=your_secret_key`


3. **Initialize and apply Terraform:**

   `terraform init`
   
   `terraform validate`
   
   `terraform plan`
   
   `terraform apply`

4. **Wait a few minutes until the app is reachable on the EC2 public IP via port 80.**

5. **Test API endpoints using Postman:**

   -Update the base URL with your EC2 public IP

   -Run requests to verify the app is up


   **ğŸ” Notes**

   -No credentials are hardcoded in the repo

   -Root user was used only for demo purposes

   -Elastic IP not used (public IP will change if instance is stopped)

   **ğŸ” Your Output Should Look Like:**

   **âœ… API Working via Postman:**

   ![Java App Output](Output_ss/postman_.png)

   **âœ… JAVA App deployment Through Browser:**
  ![Java App_browser_Output](Output_ss/ec2-deployed.png)
   
 **âœ… After all the setup don't forget to run:**(for cost-saving)
 
   `terraform destroy`

# âœ… Techeazy AWS Internship -DevOps Assignment 2 
#    IAM, S3, Log Upload (Completed)

## ğŸ“Œ Overview

This assignment automates secure log archival from EC2 instances to a private Amazon S3 bucket using Terraform and a Bash script. The project demonstrates key DevSecOps principles, including:

- IAM policy control
- EC2 lifecycle automation
- S3 lifecycle configuration
- Secure log upload and verification

---

## âœ… Completed Tasks

### ğŸ” IAM Roles

- Created two custom IAM policies:
  - `ReadOnlyAccessToS3`
  - `WriteOnlyAccessToS3`
- Attached policies to respective roles using IAM Instance Profiles for **least privilege** access.

### ğŸª£ S3 Bucket Setup

- Created a **private** S3 bucket (`techeazy-logs-bucket-nikki`)
- Enabled **block public access**
- Configured **lifecycle rule** to clean logs older than 7 days

### ğŸ’» EC2 Log Upload Automation

- Captured logs from `/var/log/my-app.log` 
- uploaded to S3 on **shutdown**
- Fully automated using:
  - Bash script: `user_data.sh.tf.tpl`
  - IAM write role

### ğŸ“‚ Terraform Code Structure

| File | Description |
|------|-------------|
| `main.tf` | EC2 and networking setup |
| `iam_role_a.tf` and `iam_role_b.tf`| IAM policies and roles |
| `s3_bucket.tf` | S3 bucket creation and lifecycle rule |
| `user_data.sh.tftpl` | Bash script for uploading logs |
| `README.md` | Documentation |

---

## ğŸ” Log Verification

- âœ… Successfully uploaded logs to S3 (`app_logs/`, `system_logs/`)
- âœ… Verified **read-only** access from another EC2 instance using the `ReadOnlyAccessToS3` IAM role through AWS-CLI

## ğŸš€ How to Deploy

`terraform init`

`terraform validate`

`terraform plan`

`terraform apply -var-file="your .tfvars file"`

# ğŸ“ Files Modified

`main.tf`

`s3_bucket.tf`

`user_data.sh.tftpl`

`dev.tfvars`

`README.md`

## ğŸ–¼ï¸ Deployment Screenshots

### âœ… Deployment Output

![EC2 deployed](Output_ss/public_ip.png)

### âœ… EC2 Instances Running
![EC2 Instances](Output_ss/ec2.png)

### âœ… S3 bucket created
![S3_bucket](Output_ss/s3_bucket.png)

### âœ… Logs in S3
![/app_logs](Output_ss/app_logs.png)
![/system_logs](Output_ss/system_logs.png)

### âœ… verify role_a
![verify role A](Output_ss/verify_role_a.png)

 **âœ… After all the setup don't forget to run:**(for cost-saving)
     `terraform destroy`

# âœ… Techeazy AWS Internship - DevOps Assignment 2 
#  IAM, S3, Log Upload (Completed)

## ğŸ“Œ Overview

This assignment automates secure log archival from EC2 instances to a private Amazon S3 bucket using Terraform and a Bash script. The project demonstrates key DevSecOps principles, including:

- IAM policy control
- EC2 lifecycle automation
- S3 lifecycle configuration
- Secure log upload and verification

---

## âœ… Completed Tasks

### ğŸ” IAM Roles

- Created two custom IAM policies:
  -ReadOnlyAccessToS3
  -WriteOnlyAccessToS3`
  -Attached policies to respective roles using IAM Instance Profiles for **least privilege** access.

### ğŸª£ S3 Bucket Setup

- Created a **private** S3 bucket (`techeazy-logs-bucket-nikki`)
- Enabled **block public access**
- Configured **lifecycle rule** to clean logs older than 7 days

### ğŸ’» EC2 Log Upload Automation

- Captured logs from `/var/log/my-app.log` 
- Uploaded to S3 on **shutdown**
- Fully automated using:
  - Bash script: `user_data.sh.tf.tpl`
  - IAM write role

### ğŸ“‚ Terraform Code Structure

| File | Description |
|------|-------------|
| `main.tf` | EC2 and networking setup |
| `iam_role_a.tf` and `iam_role_b.tf`| IAM policies and roles |
| `s3_bucket.tf` | S3 bucket creation and lifecycle rule |
| `user_data.sh.tftpl` | Bash script for uploading logs |
| `README.md` | Documentation |

---

## ğŸ” Log Verification

- âœ… Successfully uploaded logs to S3 (`app_logs/`, `system_logs/`)
- âœ… Verified **read-only** access from another EC2 instance using the `ReadOnlyAccessToS3` IAM role through AWS-CLI

## ğŸš€ How to Deploy

 `terraform init`

`terraform validate`

`terraform plan`

`terraform apply -var-file="your.tfvars file"`

### Files Modified

 `main.tf`

 `s3_bucket.tf`

 `user_data.sh.tftpl`

 `dev.tfvars`

 `README.md`

## ğŸ“¸ **Deployment Screenshots**

### âœ… Deployment Output

![Successfully Deployed](Output_ss/public_ip.png)

### âœ… EC2 Instances Running

![Running Instances](Output_ss/ec2.png)

### âœ… S3 Bucket Created

![S3 Bucket](Output_ss/s3_bucket.png)

### âœ… Logs in S3

![App Logs](Output_ss/app_logs.png)

![System Logs](Output_ss/system_logs.png)

### âœ… IAM Role Verification

![Verify Role A](Output_ss/verify_role_a.png)
---

## âœ… After all the setup Done - don't forget to run:(for cost-saving)

 `terraform destroy`

## Collaborators Invited
All teammates and mentors have been added as collaborators to the GitHub repository.

## ğŸ”Pull Request Notes

Let me know if you'd like to merge the PR or wait for mentor approval.
Thank you for reviewing! ğŸ˜Š

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Collaborators Invited-
All teammates and mentors have been added as collaborators to the GitHub repository.

## ğŸ” Pull Request Notes

Let me know if you'd like to merge the PR or wait for mentor approval.
Thank you for reviewing! ğŸ˜Š

ğŸ™Œ **Author**

  Nikki Goyal
  Techeazy AWS Internship | June 2025

# ğŸš€ DevOps Internship â€“ Assignment 3  
## Terraform Infra + Java App EC2 Deployment + GitHub Actions CI/CD + S3 Logging

## âœ… Objective

Automate provisioning of AWS infrastructure using **Terraform**, deploy a **Spring Boot** application to **EC2**, set up a **CI/CD pipeline with GitHub Actions**, and configure **S3 bucket log archival** with lifecycle rules.


## ğŸ§° Tech Stack

| Technology        | Purpose                              |
|-------------------|--------------------------------------|
| Terraform         | Infrastructure as Code (IaC)         |
| AWS               | Cloud Services                       |
| GitHub Actions    | Continuous Integration/Deployment    |
| Spring Boot (Java)| Web Application                      |
| Amazon S3         | Log Storage & Lifecycle Management   |

```md
## ğŸ§¾ Folder Structure
techeazy-assignment/
â”œâ”€â”€ Output_ss/
â”‚   â”œâ”€â”€ app_logs.png
â”‚   â”œâ”€â”€ ec2-deployed.png
â”‚   â”œâ”€â”€ ec2.png
â”‚   â”œâ”€â”€ postman.png
â”‚   â”œâ”€â”€ public_ip.png
â”‚   â”œâ”€â”€ s3_bucket.png
â”‚   â”œâ”€â”€ system_logs.png
â”‚   â””â”€â”€ verify_role_a.png
â”‚
â”œâ”€â”€ ec2-deployment/
â”‚   â”œâ”€â”€ iam_instance_profile.tf
â”‚   â”œâ”€â”€ iam_role_a.tf
â”‚   â”œâ”€â”€ iam_role_b.tf
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ output.tf
â”‚   â”œâ”€â”€ s3_bucket.tf
â”‚   â”œâ”€â”€ vpc.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ terraform.tfstate
â”‚   â”œâ”€â”€ terraform.tfstate.backup
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ user_data.sh.tftpl
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml
â”‚
â”œâ”€â”€ Techeazy AWS internship API.postman_collection (1).json
â””â”€â”€ README.md
```


## ğŸ” GitHub Secrets Used

| Secret Name           | Purpose                      |
|-----------------------|------------------------------|
| `AWS_ACCESS_KEY_ID`   | Access key for AWS IAM user  |
| `AWS_SECRET_ACCESS_KEY` | Secret key for AWS IAM user|


## ğŸ—ï¸ Infrastructure Overview

Provisioned using **Terraform**:

- **Custom VPC**     
- **Security Group**: Allows inbound **HTTP (80)** and **SSH (22)**  
- **EC2 Instance**: ubuntu, `t2.micro`, bootstrapped via `user_data.sh`  
- **S3 Bucket**: For log uploads  
- **IAM Role** + **Instance Profile**: Allows EC2 to upload logs to S3  
- **S3 Lifecycle Rule**: Automatically deletes logs after 30 days  

---

## âš™ï¸ EC2 Bootstrapping (user_data.sh.tftpl)

Upon launch, EC2 performs:

1. Installs **Java**, **Maven**, and **AWS CLI**
2. Clones the GitHub repo (`${REPO_URL}`)
3. Builds the app using `mvn clean install`
4. Starts the app on **port 80**
5. Uploads logs:
   - `/var/log/cloud-init.log` â†’ `s3://<log_s3_bucket_name>/system_logs/cloud-init-log`
   - `/var/log/my-app.log` â†’ `s3://<log_s3_bucket_name>/app_logs/my-app-log`
6. Signals app readiness by uploading `app_ready.txt` to:
   - `s3://<log_s3_bucket_name>/status/app_ready.txt`
7. Auto-shutdown after defined time (`shutdown_after_minutes`)

---

## ğŸ“¤ Final Git Commit

`git add .`

`git commit -m "âœ… Final Assignment 3: Full Terraform Infra + Java EC2 App + GitHub Actions CI/CD + S3 Logs"`

`git push origin feature/assignment-3`

## ğŸ” GitHub Actions CI/CD Workflow

### ğŸ¯ Trigger  
Runs on **push** to `feature/assignment-3` branch

### ğŸ§± Steps:

1. Checkout repository
2. Set up AWS credentials from **GitHub Secrets**
3. Run Terraform (`init`, `apply`) using `dev.tfvars`
4. Get EC2 public IP
5. Wait for EC2 to upload `app_ready.txt` to S3
6. Validate HTTP 200 response from the app URL
7. Mark workflow as **success**

---

## âœ… CI/CD Highlights

- âœ… **Fully automated** from provisioning to validation  
- ğŸ”’ **Secure** â€“ uses IAM roles and GitHub Secrets  
- ğŸ•µï¸â€â™‚ï¸ **Smart wait** â€“ waits for EC2 readiness via S3 signal  
- âš™ï¸ **Dynamic IP detection** â€“ no hardcoding

## ğŸ§© Steps in `.github/workflows/deploy.yml`
1. **Checkout Code**
2. **Setup Terraform**
3. **Configure AWS Credentials**
4. **Terraform Init**
5. **Terraform Plan -var-files="stage.tfvars(dev.tfvars)"**
6. **Terraform apply -var-files="stage.tfvars(dev.tfvars)"**
7. **Check App Health via curl & Browser**
8. **Finish**

## ğŸ“¸ Screenshots & Proofs

### 1ï¸âƒ£ EC2 Instance Running  
âœ… Java app successfully launched an EC2 instance.

   ![EC2 deployed](Output_ss/ec2_vpc_run.png)

### 2ï¸âƒ£ Logs in S3  
âœ… Logs like `cloud-init.log`, `my-app.log`, and `app_ready.txt` found under correct prefixes.
ğŸ“‚ Example S3 paths:
- `s3://<your-bucket-name>/system_logs/cloud-init.log`  
- `s3://<your-bucket-name>/app_logs/my-app.log`  
- `s3://<your-bucket-name>/status/app_ready.txt`
   

   **Lists of logs in s3 bucket**
    ![logs_lists](Output_ss/s3_logs.png)

   **App_logs**
    ![app_logs](Output_ss/auto_app_logs.png)

   **System_logs**
    ![sytem_logs](Output_ss/auto_system_logs.png)


### 3ï¸âƒ£ GitHub Actions â€“ CI/CD  
âœ… All steps executed, including waiting for readiness and validating the app endpoint.

   ![Successfull_workflow](Output_ss/gitflow.png)
  ![WorkFlow](Output_ss/workflow_run.png)

### 4ï¸âƒ£ Spring Boot App Live on EC2  
âœ… Application accessible via public IP over **port 80**  
ğŸ“ `http://<ec2-public-ip>` â†’ Returns **HTTP 200**

   ![EC2 deployed](Output_ss/java_app_3.png)

---

## ğŸ§¹ Cleanup

To avoid AWS charges, run:

`terraform destroy`

## âœ… Final Output Summary

| Output                         | Value / Status                 |
|--------------------------------|--------------------------------|
| EC2 Public IP                  | http://<your-ec2-ip>           |
| S3 Log Upload                  | âœ… Successful                   |
| Application Health             | âœ… HTTP 200 OK                  |
| Terraform Apply                | âœ… Success                      |
| GitHub Actions CI/CD Pipeline | âœ… All steps passed             |

## âœ¨ Author

ğŸ‘©â€ğŸ’» **Nikki Goyal**  
ğŸ“ Role: AWS DevOps Intern â€“ TechEazy Consulting  
ğŸ’¡ Skills: AWS | Terraform | GitHub Actions | DevOps | CI/CD | Java | S3  
ğŸ”— LinkedIn: [linkedin.com/in/nikki-goyal-devops](https://www.linkedin.com/in/nikki-goyal-devops)

#  ğŸš€ Techeazy AWS Internship â€“ Devops- Assignment 4 
# ğŸš€ Multi-Stage Infrastructure Deployment with Terraform & GitHub Actions

This project automates a **multi-stage (dev and prod) deployment** system using:

- ğŸ§± **Terraform** for provisioning AWS resources  
- â˜ï¸ **AWS EC2, IAM, S3**  
- ğŸ¤– **GitHub Actions** for CI/CD  
- ğŸ” Secure integration of both private and public GitHub repositories

---

## ğŸ§© What This Project Does

- Sets up reusable AWS infrastructure using Terraform
- Handles both **development** and **production** environments via Terraform workspaces
- Clones the application source code from:
  - a **public GitHub repo** for the `dev` stage
  - a **private GitHub repo** for the `prod` stage
- Deploys a Java web application on EC2 instance
- Uploads logs to a **single shared S3 bucket**, organized by stage
- Performs **health checks** using a status file
- Automatically shuts down EC2 instance after a configurable time

---

## âš™ï¸ How It Works

- Terraform provisions:
  - EC2 instance with startup script (user_data)
  - IAM Roles a & b with instance profile
  - Shared **S3 bucket** (created once and reused by both stages)
- GitHub Actions:
  - Handles CI/CD for both stages
  - Uploads logs from EC2 to S3 in stage-based folders
    ```
    s3://<shared-bucket>/<stage>/logs/
    s3://<shared-bucket>/<stage>/status/
    ```
  - `dev` stage uses public repo â€” no GitHub token needed
  - `prod` stage uses private repo â€” requires GitHub token
- Health check:
  - Script uploads `app_ready.txt` in the corresponding stage folder to confirm successful deployment

> âœ… Logs from both `dev` and `prod` are stored in **the same S3 bucket**, but **under their own separate folders** based on stage â€” no duplication or conflicts.

---

## ğŸ” GitHub Secrets Required

Create these secrets in GitHub Actions:

| Name                    | Description                               |
|-------------------------|-------------------------------------------|
| `AWS_ACCESS_KEY_ID`     | AWS IAM user's access key                 |
| `AWS_SECRET_ACCESS_KEY` | AWS IAM user's secret access key          |
| `PRIVATE_REPO_TOKEN`    | GitHub token for accessing private repo   |
| `PRIVATE_REPO`          | username/repo_name for `prod` stage       |
| `PUBLIC_REPO`           | username/repo_name for `dev` stage        | 

---

## ğŸ› ï¸ What You Need To Do

Before running the workflow:

- âœ… Set up a **public GitHub repo** for `dev` (can be the provided one)
- âœ… Fork and make a **private GitHub repo** for `prod` stage
- âœ… Configure your AWS IAM user with EC2, S3, and IAM access
- âœ… Add the above **GitHub Secrets** to your repository

---

## ğŸš¦ Workflow Usage

You can trigger the deployment in two ways:

### 1. âœ… **Automatic Trigger**
Push a Git tag to run the workflow:
- `deploy-dev` â†’ runs deployment for the dev stage
- `deploy-prod` â†’ runs deployment for the prod stage

### 2. ğŸ”˜ **Manual Trigger**
Go to **GitHub Actions â†’ Run workflow**:
- Select your desired `stage` (dev or prod)
- Click **Run workflow**

> âš ï¸ Run the `dev` stage first â€” it creates the shared resources like S3, IAM, etc.  
> Then run the `prod` stage, which **reuses** those resources using `data` blocks in Terraform.

---

## ğŸ“‚ S3 Logs & Status

After each deployment:

- Logs go to:
s3://<your-shared-bucket>/dev/logs/ 
s3://<your-shared-bucket>/prod/logs/

- App readiness file is uploaded as:

s3://<your-shared-bucket>/dev/status/app_ready.txt 
s3://<your-shared-bucket>/prod/status/app_ready.txt

---

---

## ğŸ“¸ Screenshots

> ğŸ“ All screenshots are stored in: `output-4/`

### âœ… Running Instances for dev/prod
![Instances for both dev/prod are running](output-4/dev-prod-instance.png)

### âœ… Successfull deployment for dev
![Successfull deployment for dev](output-4/dev_stage_ec2_deployed.png)

### âœ… Successfull deployment for prod
![Successfull deployment for prod](output-4/prod_stage_ec2_deployed.png)

### âœ… S3 Logs (Dev and Prod)
![S3 Logs dev/prod](output-4/dev_prod_logs.png)

### âœ… GitHub Actions - Dev
![GitHub Actions Dev](output-4/dev_workflow.png)

### âœ… GitHub Actions - Prod
![GitHub Actions Prod](output-4/prod_workflow.png)

### âœ… Successfull Workflow for both stage-dev/prod
![workflow sucsess for both stages](output-4/dev_prod_workflow.png)


## âœ… Final Notes

- Dev stage creates resources. Prod stage **reuses** them via `data` blocks
- IAM instance profile and roles are **shared** between both environments
- GitHub token is **not hardcoded** â€” it is securely passed as a secret only in `prod`
- S3 bucket is **common** across both stages and separated logically by folder structure
- Health validation waits for `app_ready.txt` before passing

# ğŸš€ TechEazy AWS Internship - Devops Assignment 5 â€“ 
# ğŸš€ CloudWatch Monitoring and Alerts with Multi-Stage Deployment

This assignment extends the previous infrastructure to implement **CloudWatch-based log monitoring**, **metric filtering**, and **SNS alerts** in a multi-stage setup (`dev`, `prod`) using Terraform and GitHub Actions.

---

## ğŸ¯ Objective

- Upload EC2 instance logs to **CloudWatch Logs**
- Filter logs for `Error` and `Exception` keywords
- Create **SNS topic** and email alert on log match
- Download **CloudWatch Agent config** from GitHub
- Automatically deploy and validate using **GitHub Actions**

---

## ğŸ› ï¸ What Was Implemented

### ğŸ”¸ CloudWatch Integration
- Installed **Amazon CloudWatch Agent** via `user_data`
- Downloaded config file from GitHub based on selected stage
- Pushed logs like `/var/log/messages` and `/var/log/cloud-init.log` to CloudWatch

### ğŸ”¸ Metric Filter & Alarm (manual)
- Metric filter (for `Error`, `Exception`) added manually via Console
- Alarm created to trigger email via SNS when error detected

### ğŸ”¸ IAM Role Update
- Reused existing IAM role (Role B)
- Attached **combined policy** for S3 upload + CloudWatch logging

### ğŸ”¸ SNS Setup
- Created SNS topic and email subscription
- Confirmed email for notifications

### ğŸ”¸ Terraform Files Updated/Created
- `main.tf`: EC2 deployment and logging setup
- `cloudwatch.tf`: Log group and agent config
- `iam.tf`: CloudWatch permissions added to Role B
- `sns.tf`: SNS topic and subscription
- `user_data_cloudwatch.sh.tftpl`: Boot script for agent + app
- `cloudwatch-config.json`: Fetched dynamically per stage
- `dev.tfvars` / `prod.tfvars`: Configurable per environment

### ğŸ”¸ GitHub Workflow Reused
- Used same **`deploy.yml`** from Assignment 4 for CI/CD
- Based on stage, downloaded public/private repo and config

---

## ğŸ“Œ Important Notes

- Metric filter must be created **after logs start appearing**
- CloudWatch config is downloaded from GitHub (not S3)
- SNS topic requires email confirmation to work
- No new IAM instance profile â€” reused existing from Assignment 4
- Terraform destroy **does not delete log groups** (needs manual cleanup or extra config)

---

## âœ… Final Outputs (Assignment 5)

- [x] EC2 deployed with log agent
- [x] Logs uploaded to CloudWatch
- [x] SNS topic created and confirmed
- [x] Metric filter manually tested
- [x] Email alert received on error log
- [x] Working across `dev` and `prod`
